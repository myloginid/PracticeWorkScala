package com.internal.spark.rdd

import java.io.BufferedReader;
import java.io.InputStream;
import java.io.InputStreamReader;
//
import org.apache.log4j.Logger;
//import org.dataalgorithms.util.InputOutputUtil;

/**
 *  The InputStreamReaderRunnable class captures
 *  the output streams generated by submitting a
 *  Spark job (from a Java code) to a Spark Cluster.
 *
 *
 *  @author Mahmoud Parsian (mahmoud.parsian@yahoo.com)
 *
 */

class InputStreamReaderRunnable(is: InputStream, name: String) extends Runnable {
  var name = null;
  var reader: BufferedReader = null;

  this.name = name;
  this.reader = new BufferedReader(new InputStreamReader(is));
  println("InputStreamReaderRunnable:  name=" + name);

  @Override
  def run() {
    try {
      var line = reader.readLine();
      while (line != null) {
        println(line);
        line = reader.readLine();
      }
    } catch {
      case e: Exception => {
        println("run() failed. for name=" + name, e);
      }

    } finally {
      reader.close()
    }
  }
}